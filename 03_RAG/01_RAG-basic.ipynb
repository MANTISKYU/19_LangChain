{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Downloading PyMuPDF-1.24.12-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Downloading PyMuPDF-1.24.12-cp39-abi3-win_amd64.whl (16.0 MB)\n",
      "   ---------------------------------------- 0.0/16.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/16.0 MB 12.5 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.8/16.0 MB 4.0 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 5.8/16.0 MB 9.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.3/16.0 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.7/16.0 MB 9.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.8/16.0 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.5/16.0 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 16.0/16.0 MB 9.7 MB/s eta 0:00:00\n",
      "Installing collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.24.12\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문서 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 페이지 수 : 6\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(\"data/snow-white.pdf\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"문서의 페이지 수 : {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "백설공주\n",
      "옛날어느왕국에공주님이태어났어요.\n",
      "“어쩜이렇게어여쁠까? 살결이눈처럼하얗구나. 백\n",
      "설공주라고불러야겠다.”\n",
      "왕과왕비는갓태어난딸을보며기뻐했어요.\n",
      "하지만기쁨도잠시, 왕비는곧세상을떠나고말았어\n",
      "요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': None, 'metadata': {'source': 'data/snow-white.pdf', 'file_path': 'data/snow-white.pdf', 'page': 0, 'total_pages': 6, 'format': 'PDF 1.5', 'title': 'PowerPoint 프레젠테이션', 'author': 'PC', 'subject': '', 'keywords': '', 'creator': 'Microsoft® PowerPoint® 2013', 'producer': 'Microsoft® PowerPoint® 2013', 'creationDate': \"D:20230912112024+09'00'\", 'modDate': \"D:20230912112024+09'00'\", 'trapped': ''}, 'page_content': '백설공주\\n옛날어느왕국에공주님이태어났어요.\\n“어쩜이렇게어여쁠까? 살결이눈처럼하얗구나. 백\\n설공주라고불러야겠다.”\\n왕과왕비는갓태어난딸을보며기뻐했어요.\\n하지만기쁨도잠시, 왕비는곧세상을떠나고말았어\\n요.\\n', 'type': 'Document'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문서 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 청크의 수 : 21\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=10)\n",
    "\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"분할된 청크의 수 : {len(split_documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DB생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.9.0-cp311-cp311-win_amd64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\20112\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\20112\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Downloading faiss_cpu-1.9.0-cp311-cp311-win_amd64.whl (14.9 MB)\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 3.7/14.9 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.4/14.9 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.7/14.9 MB 28.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.9/14.9 MB 24.6 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding = embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저녁이되자, 일곱난쟁이가돌아왔어요.\n",
      "난쟁이들은쓰러진백설공주를보고엉엉울었어요.\n",
      "백설공주는깊은잠에빠진것처럼보였지요.\n",
      "“백설공주님, 못된왕비의꾐에넘어갔군요.”\n",
      "간사과랍니다. 잠깐문을열어보세요.”\n",
      "백설공주는고개를저었어요.\n",
      "“난쟁이들이문을열어주지말라고했어요.”\n",
      "백설공주가거절하자, 왕비는창문틈새로사과를쑥내밀었어\n",
      "요.\n",
      "왕자는깨어난백설공주를보고기뻐했어요.\n",
      "“공주님, 나는이웃나라왕자입니다.”\n",
      "“왕자님이나를다시살려주셨군요.”\n",
      "“나와결혼해주시겠어요?”\n",
      "“네, 좋아요!”\n",
      "밤이되자오두막주인인일곱난쟁이가돌아왔어요.\n",
      "난쟁이들은집안이어질러진것을보고깜짝놀랐지요.\n",
      "일곱째난쟁이가큰소리로외쳤어요.\n",
      "“누가내침대에서자고있어!”\n"
     ]
    }
   ],
   "source": [
    "for doc in vectorstore.similarity_search(\"난쟁이\"):\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/snow-white.pdf', 'file_path': 'data/snow-white.pdf', 'page': 0, 'total_pages': 6, 'format': 'PDF 1.5', 'title': 'PowerPoint 프레젠테이션', 'author': 'PC', 'subject': '', 'keywords': '', 'creator': 'Microsoft® PowerPoint® 2013', 'producer': 'Microsoft® PowerPoint® 2013', 'creationDate': \"D:20230912112024+09'00'\", 'modDate': \"D:20230912112024+09'00'\", 'trapped': ''}, page_content='백설공주\\n옛날어느왕국에공주님이태어났어요.\\n“어쩜이렇게어여쁠까? 살결이눈처럼하얗구나. 백\\n설공주라고불러야겠다.”\\n왕과왕비는갓태어난딸을보며기뻐했어요.'),\n",
       " Document(metadata={'source': 'data/snow-white.pdf', 'file_path': 'data/snow-white.pdf', 'page': 4, 'total_pages': 6, 'format': 'PDF 1.5', 'title': 'PowerPoint 프레젠테이션', 'author': 'PC', 'subject': '', 'keywords': '', 'creator': 'Microsoft® PowerPoint® 2013', 'producer': 'Microsoft® PowerPoint® 2013', 'creationDate': \"D:20230912112024+09'00'\", 'modDate': \"D:20230912112024+09'00'\", 'trapped': ''}, page_content='저녁이되자, 일곱난쟁이가돌아왔어요.\\n난쟁이들은쓰러진백설공주를보고엉엉울었어요.\\n백설공주는깊은잠에빠진것처럼보였지요.\\n“백설공주님, 못된왕비의꾐에넘어갔군요.”'),\n",
       " Document(metadata={'source': 'data/snow-white.pdf', 'file_path': 'data/snow-white.pdf', 'page': 4, 'total_pages': 6, 'format': 'PDF 1.5', 'title': 'PowerPoint 프레젠테이션', 'author': 'PC', 'subject': '', 'keywords': '', 'creator': 'Microsoft® PowerPoint® 2013', 'producer': 'Microsoft® PowerPoint® 2013', 'creationDate': \"D:20230912112024+09'00'\", 'modDate': \"D:20230912112024+09'00'\", 'trapped': ''}, page_content='왕자는백설공주에게반해유리관을달라고부탁했어요.\\n일곱난쟁이는백설공주를잘지킨다는약속을받고유리관을\\n내주었지요.\\n그런데신하들이유리관을옮기다돌부리에툭! 백설공주목\\n에서사과조각이툭!'),\n",
       " Document(metadata={'source': 'data/snow-white.pdf', 'file_path': 'data/snow-white.pdf', 'page': 3, 'total_pages': 6, 'format': 'PDF 1.5', 'title': 'PowerPoint 프레젠테이션', 'author': 'PC', 'subject': '', 'keywords': '', 'creator': 'Microsoft® PowerPoint® 2013', 'producer': 'Microsoft® PowerPoint® 2013', 'creationDate': \"D:20230912112024+09'00'\", 'modDate': \"D:20230912112024+09'00'\", 'trapped': ''}, page_content='간사과랍니다. 잠깐문을열어보세요.”\\n백설공주는고개를저었어요.\\n“난쟁이들이문을열어주지말라고했어요.”\\n백설공주가거절하자, 왕비는창문틈새로사과를쑥내밀었어\\n요.')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver.invoke(\"백설공주와 일곱난쟁이는 어디서 만났어?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프롬프트 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "당신은 질문 답변 작업을 위한 어시스턴트입니다\n",
    "주어진 문맥을 사용하여 질문에 답변하세요\n",
    "유치원 선생님이 아이에게 말하는 것처럼 매우 친절하고 부드러운 어조를 사용하세요\n",
    "따뜻하고 친근한 방식으로 말하세요\n",
    "답을 모르는 경우에는 모른다고 말하세요\n",
    "한국어로 말하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "Use a very kind and gentle tone like a kindergarten teacher talking to a child.\n",
    "Speak in a warm and friendly way.\n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chain 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriver, \"question\": RunnablePassthrough()}\n",
    "    |prompt\n",
    "    |llm\n",
    "    |StrOutputParser()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "친구야, 백설공주가 왕비보다 더 아름답다고 요술거울이 말했단다. 그래서 왕비님이 조금 화가 나셨지요. 하지만 우리 모두는 각자 다르게 아름답다는 걸 기억해야 해요. 😊\n"
     ]
    }
   ],
   "source": [
    "question = \"백설공주와 왕비 중 누가 더 아름더워?\"\n",
    "response = chain.invoke(question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10월호 산업동향 관련 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 페이지 수 : 25\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "PracticeLoader = PyMuPDFLoader(\"data/SPRi AI Brief_10월호_산업동향_F.pdf\")\n",
    "\n",
    "PracticeDocs = PracticeLoader.load()\n",
    "\n",
    "print(f\"문서의 페이지 수 : {len(PracticeDocs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024년 10월호\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(PracticeDocs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': None, 'metadata': {'source': 'data/SPRi AI Brief_10월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_10월호_산업동향_F.pdf', 'page': 0, 'total_pages': 25, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.13947', 'producer': 'Hancom PDF 1.3.0.547', 'creationDate': \"D:20241007090546+09'00'\", 'modDate': \"D:20241007090546+09'00'\", 'trapped': ''}, 'page_content': '2024년 10월호\\n', 'type': 'Document'}\n"
     ]
    }
   ],
   "source": [
    "print(PracticeDocs[0].__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 청크의 수 : 499\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=10)\n",
    "\n",
    "practice_split_documents = text_splitter.split_documents(PracticeDocs)\n",
    "\n",
    "print(f\"분할된 청크의 수 : {len(practice_split_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "practiceEmbeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "practiceVectorstore = FAISS.from_documents(documents=practice_split_documents, embedding = practiceEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∙인물 이미지 생성 기능은 제미나이 어드밴스드, 비즈니스, 엔터프라이즈 이용자를 대상으로 영어로 \n",
      "우선 제공되며 향후 지원 언어와 이용자 범위를 확대할 계획\n",
      "실현하기 위한 권고안을 담은 ‘인류를 위한 AI 거버넌스’ 최종 보고서를 발간\n",
      "방식 대신 다른 방식을 시도하는 방법 등을 학습해 추론 능력을 비약적으로 향상\n",
      "애니메이션 등 다양한 스타일의 이미지를 생성하며, 이마젠 2보다 이미지 생성 기능이 대폭 향상\n"
     ]
    }
   ],
   "source": [
    "for PracticeDoc in practiceVectorstore.similarity_search(\"거버넌스\"):\n",
    "    print(PracticeDoc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "practiceRetriever = practiceVectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/SPRi AI Brief_10월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_10월호_산업동향_F.pdf', 'page': 14, 'total_pages': 25, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.13947', 'producer': 'Hancom PDF 1.3.0.547', 'creationDate': \"D:20241007090546+09'00'\", 'modDate': \"D:20241007090546+09'00'\", 'trapped': ''}, page_content='n 옥스퍼드⼤ 연구진에 따르면 AI 개발에 필수적인 GPU 클러스터는 미국과 중국을 중심으로 \\n전 세계 30개국에 집중되어 있으며, 대부분 지역에는 GPU 클러스터가 부재'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_10월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_10월호_산업동향_F.pdf', 'page': 14, 'total_pages': 25, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.13947', 'producer': 'Hancom PDF 1.3.0.547', 'creationDate': \"D:20241007090546+09'00'\", 'modDate': \"D:20241007090546+09'00'\", 'trapped': ''}, page_content='∙중국은 GPU 클러스터를 보유한 지역 수에서 미국을 앞서나, 대중국 수출이 제한된 엔비디아\\n(NVIDIA)의 H100과 같은 첨단 GPU를 임대할 수 있는 지역은 미국에 집중'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_10월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_10월호_산업동향_F.pdf', 'page': 14, 'total_pages': 25, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.13947', 'producer': 'Hancom PDF 1.3.0.547', 'creationDate': \"D:20241007090546+09'00'\", 'modDate': \"D:20241007090546+09'00'\", 'trapped': ''}, page_content='<퍼블릭 클라우드 사업자의 GPU 클러스터 글로벌 분포 현황> \\nn 연구 결과는 AI 시스템에 차세대 지정학적 경쟁뿐 아니라 전 세계 AI 거버넌스에도 중요한 의미를 내포'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_10월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_10월호_산업동향_F.pdf', 'page': 14, 'total_pages': 25, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.13947', 'producer': 'Hancom PDF 1.3.0.547', 'creationDate': \"D:20241007090546+09'00'\", 'modDate': \"D:20241007090546+09'00'\", 'trapped': ''}, page_content='사업을 통해 임대 가능한 GPU 클러스터의 물리적 위치를 바탕으로 AI 칩의 글로벌 분포 현황을 조사\\n  * AWS, 구글, 마이크로소프트, 알리바바, 화웨이, 텐센트')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "practiceRetriever.invoke(\"GPU 클러스터는 어디에 집중되어 있어?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "practicePrompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "Use a very kind and gentle tone like a kindergarten teacher talking to a child.\n",
    "Speak in a warm and friendly way.\n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Context: \n",
    "{practiceContext}\n",
    "\n",
    "#Question:\n",
    "{practiceQuestion}\n",
    "\n",
    "#Answer:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "practiceLlm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "    {\"practiceContext\": retriver, \"practiceQuestion\": RunnablePassthrough()}\n",
    "    |practicePrompt\n",
    "    |practiceLlm\n",
    "    |StrOutputParser()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미안하지만, 로니 콜먼의 3대 중량에 대한 정보는 여기에서 찾을 수 없어요. 다른 질문이 있으면 언제든지 물어봐 주세요!\n"
     ]
    }
   ],
   "source": [
    "practiceQuestion = \"로니콜먼의 3대중량은 어떻게 돼?\"\n",
    "practiceResponse = chain.invoke(practiceQuestion)\n",
    "\n",
    "print(practiceResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코히어 연구는 캐나다에서 성공했어요. 😊\n"
     ]
    }
   ],
   "source": [
    "practiceQuestion = \"코히어 연구는 어느나라에서 성공했어?\"\n",
    "practiceResponse = chain.invoke(practiceQuestion)\n",
    "\n",
    "print(practiceResponse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
